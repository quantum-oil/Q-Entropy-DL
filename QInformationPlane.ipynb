{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#useful-definitions\" data-toc-modified-id=\"useful-definitions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>useful definitions</a></span></li><li><span><a href=\"#setting-the-DNN-stage\" data-toc-modified-id=\"setting-the-DNN-stage-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>setting the DNN stage</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# useful definitions \n",
    "\n",
    "[Reference](https://lilianweng.github.io/lil-log/2017/09/28/anatomize-deep-learning-with-information-theory.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Kullback - Leibler distance may be expressed by the formula\n",
    "\n",
    "$D_{KL} [p(X)||p(Y)] = \\sum p(x) Log\\left( \\frac{p(X)}{p(Y)} \\right) $\n",
    "\n",
    "Mutual Information is a measure for how much one may learn about some random variable X given the knowledge of some other variable Y; Mutual information is defined as\n",
    "\n",
    "$ I(X,Y) = D_{KL} [p(X,Y)||p(X)p(Y)] $\n",
    "\n",
    "$I(X,Y) =   \\sum p(X,Y) Log \\left(\\frac{p(X,Y)}{p(X)p(Y)}\\right) = \\sum p(X,Y) Log \\left(\\frac{p(X|Y)}{p(X)}\\right) $\n",
    "\n",
    "$I(X,Y) = H(X) - H(X|Y) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized KL distance for Tsallis Statistics can be written as\n",
    "\n",
    "$D_{KL_q} [p(x)||p(y)] = \\sum p(x)  \\frac{\\left(\\frac{p(x)}{p(y)}\\right)^{q-1}  -1}{q-1} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, Generalized Mutual Information in Tsallis Statistcs becomes\n",
    "\n",
    "$ I_q(X,Y) = D_{KL_q} [p(X,Y)||p(X) p(Y)] \\\\\n",
    "D_{KL_q} [p(X,Y)||p(X) p(Y)] = \\sum p(X,Y)  \\frac{\\left(\\frac{p(X,Y)}{p(X)p(Y)}\\right)^{q-1}  -1}{q-1} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting the DNN stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multidimensional Variables $X$ and $Y$ shall be used to designate respectively the dataset and its labels.\n",
    "\n",
    "Following Tishby's approach we shall treat each layer of the dense network as a single random variable $T_i$, since in dense networks each neuron is connected to the whole set of inputs as well as the outputs.\n",
    "\n",
    "We are interested in understanding the evolution of layer weigths in a simple Dense Neural Network using the Information Plane, where we shall plot $I(X,T) \\, x \\, I(Y,T)$ then compare to the results of plotting $I_q(X,T) \\, x \\, I_q(Y,T) $ for a representative set of $q$ values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import reuters\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0112 10:28:12.275921 139835290920768 deprecation_wrapper.py:119] From /home/nahum/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0112 10:28:12.388080 139835290920768 deprecation_wrapper.py:119] From /home/nahum/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0112 10:28:12.452216 139835290920768 deprecation_wrapper.py:119] From /home/nahum/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0112 10:28:12.521543 139835290920768 deprecation_wrapper.py:119] From /home/nahum/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0112 10:28:12.584271 139835290920768 deprecation_wrapper.py:119] From /home/nahum/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "ntrain = 60000\n",
    "ntest = 10000\n",
    "\n",
    "#reducing dataset\n",
    "X_train = X_train[0:ntrain]\n",
    "y_train = y_train[0:ntrain]\n",
    "\n",
    "X_train = X_train.reshape(ntrain, 784)\n",
    "X_test = X_test.reshape(ntest, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing \n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#one-hot encoding\n",
    "n_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))                            \n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Files(model, dirname, model_filename):\n",
    "        \"\"\"Save model on a directory.\n",
    "        \n",
    "        Parameters\n",
    "        ----------------------------------------\n",
    "        model: Keras model\n",
    "        dirname: Name of the directory that you\n",
    "                 want to put your files in.\n",
    "        model_filename: Name of the file.\n",
    "        \n",
    "        \"\"\"\n",
    "        if not dirname in os.listdir(os.getcwd()):\n",
    "            try:\n",
    "                os.makedirs(dirname) #create your directory\n",
    "            except OSError as exc: \n",
    "                if exc.errno != errno.EEXIST:\n",
    "                    raise \"ERROR!\"\n",
    "        try:\n",
    "            path = os.getcwd() + '/data'        \n",
    "            #os.chdir(path)\n",
    "            model_path = os.path.join(path, model_filename)\n",
    "            model.save(model_path)\n",
    "            #os.chdir('..')\n",
    "        \n",
    "        except:\n",
    "            raise \"ERROR!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 20;\n",
    "caminho = os.getcwd()\n",
    "save_dir = caminho \n",
    "for i in range(0,epocas):\n",
    "    model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=1,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, Y_test))\n",
    "    model_filename = 'keras_mnistepoca' + str(i) + '.h5'\n",
    "    Write_Files(model, 'data', model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the joint proability $P(X,Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PX(nbins):\n",
    "\n",
    "    hists = []\n",
    "    breaks = []\n",
    "\n",
    "    for i in range(0,len(X_train[1])): \n",
    "        hist = np.histogram(np.transpose(X_train)[i],bins = nbins);\n",
    "        hists.append(hist[0])\n",
    "        breaks.append(hist[1])\n",
    "    \n",
    "    return hists , breaks  \n",
    "\n",
    "#calculando a probabilidade conjunta\n",
    "\n",
    "def PXY(nbins):\n",
    "\n",
    "    Px, binsX =  PX(30)\n",
    "    \n",
    "    histy = np.histogram(y_train, bins=10)[0]\n",
    "    Py = histy[0]\n",
    "    binsY = histy[1]\n",
    "    \n",
    "    for i in range(0,10):\n",
    "        indices = np.where(y_train==i)\n",
    "        \n",
    "        pxdadoy =[]\n",
    "        breaks = []\n",
    "        \n",
    "        hist = np.histogram(np.transpose(X_train[indices])[i],bins = nbins);\n",
    "        pxdadoy.append(hist[0])\n",
    "        breaks.append(hist[1])\n",
    "\n",
    "        PXY.append(pxdadoy*Py[i])\n",
    "            \n",
    "    return PXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Markov chain\n",
    "\n",
    "$Y \\rightarrow X \\rightarrow T_i$\n",
    "\n",
    "to get\n",
    "\n",
    "$P(T_i,X) = P(T_i|X) P(X)$\n",
    "\n",
    "and\n",
    "\n",
    "$P(T_i,Y) = \\sum P(X,Y) P(T_i | X) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get outputs of activation functions and get $T_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-92f4e9052b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlayer_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [func([test, 1.]) for func in functors]\n",
    "print(layer_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
